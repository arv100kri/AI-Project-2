%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.0 (25/8/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage{cite} % Better citations
\usepackage{setspace}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.00} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

%\usepackage[hmarginratio=1:1,top=16mm,columnsep=20pt]{geometry} % Document margins

\usepackage[headsep=0.05in,scale=1.0,margin={0.5in,0.5in},columnsep=20pt]{geometry}
%\oddsidemargin 0.0in %%this makes the odd side margin go to the default of 1inch
%\evensidemargin 0.0in
%\headheight 0.5in
%\topmargin 0.5in
%\textheight 9.0in
%\textwidth 6.5in %%sets the textwidth to 6.5, which leaves 1 for the remaining right margin with 8 1/2X11inch paper 

\usepackage{multicol} % Used for the two-column layout of the document
%\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\renewcommand{\LettrineTextFont}{\rmfamily}
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\pagestyle{empty} % no page numbers in footer
\usepackage{scalefnt} %scale font for title
\usepackage{titlesec} % Allows customization of titles
\usepackage{comment}	%Allows addition of comments
%\usepackage[small,compact]{titlesec}
\titleformat{\section}[block]{\large\scshape\centering{\Roman{section}.}}{}{1em}{} % Change the look of the section titles 

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

%\title{\vspace{-15mm}\fontsize{20pt}{5pt}\selectfont\textbf{Experienced Search}} % Article title

%----------------------------------------------------------------------------------------

\begin{document}
%\title{\vspace{-20mm}{Recognition of Continuous Mouse Gesture Sequences}}
%\date{}
%\maketitle % Insert title
\scalefont{2}
\centerline{Recognition of Continuous Mouse Gesture Sequences}
\normalsize

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Problem Statement}

\lettrine[nindent=0em,lines=2]{G}estures are a proven form of input in many
human-centric systems. %Gestures take on many forms, including hand and arm
%gestures, head and face gestures, and body gestures \cite{mitra_gesture_2007}.
As Nielsen describes\cite{nielsen_noncommand_1993}, gestures are particularly
effective when the user interface paradigm moves away from a command-oriented
approach %(i.e., clicking toolbar buttons) %Removing this for space%
and toward a task-oriented approach.
%(i.e., double the size of this image and sharpen it). %Removing this for space%
\begin{comment}
In task-centric human-computer interaction scenarios, the user's aim is to request a sequence of
actions intended to complete a desired task. 
\end{comment}
Command-oriented user interfaces require the user to request an action 
and subsequently wait for completion, which is clearly sub-optimal when 
the desired sequence of actions is known in advance.

In our proposed system, the user draws a continuous sequence of gestures. The system recognizes each gesture in the sequence %the user interacting with the system 
%various gestures are ``drawn'' on the screen using a mouse 
%and the system tries to recognize each of those gestures from
by matching against a trained gesture database.  
%a previously known set and perform an action corresponding to that gesture. If the
%gesture is not recognized it will be added to the known set alongwith an associated action. Multiple
%gestures can be given at once and our system will discern and recognize each of them.
The primary benefit of our proposed system is its suitability for completing task-oriented work. The system provides a capability to queue 
actions for sequential execution, eliminating the need for a user to alternate
between providing input and waiting for an action to be completed, saving scarce time and resources.
\begin{comment}
%I feel we are stressing to much on the potential use of our system than the actual problem itself, hence i have removed this part
We propose a user interface for task-oriented applications that conceptualizes
the user as directing a virtual assistant. In this system, the user performs a
natural mouse-based gesture; the ``assistant'' interprets the continuous gesture
as a linear sequence of actions. We propose that complex gestures consisting of
a sequence of individual gestures provide a more intuitive user interface for
task-oriented systems. The primary benefit is to reclaim the time humans spend
waiting on the system by eliminating the need for a user to alternate between
providing input and waiting for requests actions to complete. As a result,
humans can spend time elsewhere while the system is completing a task.
\end{comment}

%------------------------------------------------
\section{Related Work}

Mitra and Acharya, in their survey on gesture recognition techniques \cite{mitra_gesture_2007}, 
note that Hidden Markov Models (HMMs) are a popular tool used to 
accurately recognize gestures in dynamic gesture recognition problems. 
Additionally, they present a categorization of gestures,
defining pantomimes as ``gestures depicting objects or actions, with or without
accompanying speech''. 

Our work is focused on the problem of using HMMs to
recognize individual pantomimes embedded in a ``composite pantomime'' (pantomime
sequence), constructed through simple mouse gestures. % I feel that we might need to emphasize that we are using the mouse to create these gestures
Yang et al \cite{yang_gesture_1994} discuss work similar to ours, with the primary 
difference being that they train HMMs on sequential gestures; in contrast, our approach 
is to exclusively train on individual gestures, which will then be used to identify 
each gesture in a gesture sequence. %sequential or composite pattern of gestures
Our approach is an extension 
to the work by Tanguay\cite{tanguay_jr_hidden_1995}; we propose to recognize 
more than one gesture given as input.

\begin{comment}
His work differs from ours primarily by focusing exclusively on gesture
recognition of individual gestures.
\end{comment}

%------------------------------------------------
\section{Proposed Implementation}

As implied above, we propose to implement a system that uses HMMs 
to recognize individual gestures within gesture sequences.
%Consistent with the related work described above, 
\begin{comment}
%Removing this for want of space
Consistent with the related work described above, the user will first perform a
training phase and subsequently use the system during a recognition phase. 
\end{comment}
In our system, the user will manually perform a \emph{single} gesture multiple times to
train an HMM. We note that the user will \emph{not} need to conduct training for
gesture sequences; eliminating that step reduces the training time and lowers
the barrier for system adoption.

During the recognition phase, the user will create multi-gesture sequences.
As Mitra et al note, %in their gesture recognition survey
a difficult aspect of this problem is segmentation ambiguity. Our proposed approach to solving the
segmentation problem is to apply a technique that aims to automatically segment
the complete data stream (representing 1..N individual gestures) into (shorter)
sub-streams (each corresponding to one gesture).
\begin{comment}
An initial segmentation step consists of splitting the complete data stream up
into N sub-streams (each corresponding to an individual gesture) with a duration
equal to the average duration of the training gestures.
\end{comment}

Initially, the data stream is split temporally into N sub-streams 
(each corresponding to an individual gesture) of identical duration equal to the 
mean time taken to draw an individual gesture.
The duration of each sub-stream can be conceptualized as a ``window'' overlaid
on the complete data stream; N sub-streams correspond to N windows. After
configuring the initial ``window set", we calculate a ``window set score" which is %I dont think we need to mention that the score will be iteratively improved
the mathematical product of individual window scores; each window score, in turn, 
is equal to the maximum of the probabilities between a given window sub-stream 
and each trained HMM. We subsequently iteratively increase the score of the window set % during 
%each step of the iteration, each window may be individually ``moved'' 
by independently increasing or decreasing the duration of each window. The decision to modify each window is determined by 
comparing the window score in iteration \emph{k} to the score in iteration \emph{k-1}. 
If the score for a given window increased, the action taken in the previous iteration (either
growing or shrinking the window) is repeated; conversely, if the score
decreased, the alternate action should be taken. In order to ensure the process terminates, each successive step in the iteration will modify the
window duration by a smaller percentage than the previous iteration.% This iterative approach seems to be
%fairly intuitive and easy to build upon for future work.
%------------------------------------------------
\section{Proposed Evaluation}

We propose to evaluate the system by conducting a micro-study involving one
user. Because our proposed work is to develop a sequential gesture recognition
algorithm, we propose to evaluate the system primarily by collecting metrics
that measure recognition accuracy. During the study, the user will complete an
initial training step and a subsequent recognition step, consisting of multiple
phases.
Recognition phase \emph{n} will consist of the user providing gesture sequences
of length \emph{n}. We will score the system by computing the proportion of
correctly identified individual gestures, where ``correct identification"
includes both placement of the individual gesture in
each gesture sequence and correct identification of the intended gesture. % and 
%compare our results with \cite{yang_gesture_1994}, \cite{tanguay_jr_hidden_1995}.
We will conduct three phases of recognition testing (thus evaluating sequential gestures with a maximum length of three), 
primarily because we anticipate three phases will provide us with enough data to determine the algorithm's effectiveness.

\begin{comment}
In addition, in order to determine the
expected length of commands, we will ask for qualitative feedback about the
usefulness of the system and a description of anticipated tasks.
\end{comment}

%----------------------------------------------------------------------------------------
\section{References}

\begin{spacing}{0.9}
\bibliographystyle{unsrt}	%I use unsrt so that the bib items appear in the order of citing
%\bibliography{myrefs}
\begingroup
\renewcommand{\section}[2]{}%
\bibliography{myrefs}
\endgroup
\end{spacing}

\end{multicols}
\end{document}

%	Member #1: Justin Permar - GT ID:902931271
%	Member #2: Arvind Krishnaa Jagannathan - GT ID: 902891874
%