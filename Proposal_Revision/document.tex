%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.0 (25/8/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage{cite} % Better citations
\usepackage{setspace}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.00} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

%\usepackage[hmarginratio=1:1,top=16mm,columnsep=20pt]{geometry} % Document margins

\usepackage[headsep=0.05in,scale=1.0,margin={0.5in,0.5in},columnsep=20pt]{geometry}
%\oddsidemargin 0.0in %%this makes the odd side margin go to the default of 1inch
%\evensidemargin 0.0in
%\headheight 0.5in
%\topmargin 0.5in
%\textheight 9.0in
%\textwidth 6.5in %%sets the textwidth to 6.5, which leaves 1 for the remaining right margin with 8 1/2X11inch paper 

\usepackage{multicol} % Used for the two-column layout of the document
%\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\renewcommand{\LettrineTextFont}{\rmfamily}
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\pagestyle{empty} % no page numbers in footer
\usepackage{scalefnt} %scale font for title
\usepackage{titlesec} % Allows customization of titles
\usepackage{comment}	%Allows addition of comments
%\usepackage[small,compact]{titlesec}
\titleformat{\section}[block]{\large\scshape\centering{\Roman{section}.}}{}{1em}{} % Change the look of the section titles 

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

%\title{\vspace{-15mm}\fontsize{20pt}{5pt}\selectfont\textbf{Experienced Search}} % Article title

%----------------------------------------------------------------------------------------

\begin{document}
%\title{\vspace{-20mm}{Recognition of Continuous Mouse Gesture Sequences}}
%\date{}
%\maketitle % Insert title
\scalefont{2}
\centerline{Recognition of Continuous Mouse Gesture Sequences}
\normalsize

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Problem Statement}
% Not really convinced that more work needs to be done
% Not much of social impact

%Discussions%
%1. Guy from McDonalds
%2. People with Carpal Tunnel
%3. Where else can our system impact the society.
%4. Let us make the system do a simple action if a gesture is recognized. This can be like printing out a line of text or something. I need to discuss this point with you.

\lettrine[nindent=0em,lines=2]{G}estures are a proven form of input in many
human-centric systems. Gestures can be captured from a wide array of sources; from 
something as simple as the movement of a mouse to something as complex as full-body motion \cite{mitra_gesture_2007}.
However, any system driven by gestures is intuitive and more effective to work with
when compared to the traditional command-oriented approach \cite{nielsen_noncommand_1993}. In scenarios involving repeatedly doing a set of tasks through a predetermined sequence of menus, clicks and dialog windows, a gesture-based paradigm of interaction with the system would provide a refreshing alternative to the user. In addition, if the system is robust in identifying the gestures with a high degree of accuracy, a gesture-based interface will be a more accessible way for people with conditions like Carpal-Tunnel to control the system.

In our proposed system, the user draws a continuous sequence of gestures using a mouse. The system recognizes each gesture in the sequence 
by matching against a trained gesture database. Once a gesture has been identified, an action associated with it is performed. However, if an unknown gesture is encountered, the user can add it to the training database alongwith an associated action.This system provides a capability to queue actions for sequential execution, eliminating the need for a user to alternate between providing input and waiting for an action to be completed, saving scarce time and resources. This is one of the primary benefits of our system, in addition to the previously mentioned potential ways to utilize it.

%------------------------------------------------
%How are/where are you references deficient
\section{Related Work}

Mitra and Acharya, in their survey on gesture recognition techniques \cite{mitra_gesture_2007}, 
note that Hidden Markov Models (HMMs) are a popular tool used to 
accurately recognize gestures in dynamic gesture recognition problems. 
Additionally, they present a categorization of gestures,
defining pantomimes as ``gestures depicting objects or actions, with or without
accompanying speech''. 

Our work is focused on the problem of using HMMs to
recognize individual pantomimes embedded in a ``composite pantomime'' (pantomime
sequence), constructed through simple mouse gestures. % I feel that we might need to emphasize that we are using the mouse to create these gestures
Yang et al \cite{yang_gesture_1994} discuss work similar to ours, in which they train their HMM model on continuous gestures of varying lengths. Once the system is trained, it is able to identify one or more gestures, based on the models constructed. However, this method has a long training duration and is not robust enough to recognize untrained symbols. Our aim is to exclusively train on individual gestures, which will then be used to identify each gesture in a gesture sequence. 

We propose to base our work on the doctoral thesis of Tanguay\cite{tanguay_jr_hidden_1995}. However, in addition to recognizing individual gestures, we plan to extend his technique to identify multiple gestures.

%This paragraph definitely requires better wording%

%------------------------------------------------
%Why does your approach make sense
\section{Proposed Implementation}

As implied above, we propose to implement a system that uses HMMs 
to recognize individual gestures within gesture sequences.

In our system, the user will manually perform a \emph{single} gesture multiple times to train an HMM. We note that the user will \emph{not} need to conduct training for
gesture sequences; eliminating that step reduces the training time and lowers
the barrier for system adoption.

During the recognition phase, the user will create multi-gesture sequences, which our system will try to recognize. As Mitra et al note, 
a difficult aspect of this problem is segmentation ambiguity. Our proposed approach to solving the segmentation problem is to apply a technique that aims to automatically segment the complete data stream (representing 1..N individual gestures) into (shorter) sub-streams (each corresponding to one gesture).

Initially, the data stream is split temporally into N sub-streams 
(each corresponding to an individual gesture) of identical duration equal to the 
mean time taken to draw an individual gesture.
The duration of each sub-stream can be conceptualized as a ``window'' overlaid
on the complete data stream; N sub-streams correspond to N windows. After
configuring the initial ``window set", we calculate a ``window set score" which is the mathematical product of individual window scores; each window score, in turn, 
is equal to the maximum of the probabilities between a given window sub-stream 
and each trained HMM. We subsequently iteratively increase the score of the window set 
by independently increasing or decreasing the duration of each window. The decision to modify each window is determined by comparing the window score in iteration \emph{k} to the score in iteration \emph{k-1}. If the score for a given window increased, the action taken in the previous iteration (either growing or shrinking the window) is repeated; conversely, if the score decreased, the alternate action should be taken. In order to ensure the process terminates, each successive step in the iteration will modify the window duration by a smaller percentage than the previous iteration.

This approach seems to be a good starting point and provides a base on exploring other ideas to tackle the problem of segmentation. In addition to our approach, we also plan to explore strategies used to identify segments in handwriting recognition \cite{zheng2002segmentation} and try to adopt it in our framework.
%Better wording perhaps%

%------------------------------------------------
%1. What are you comparing against
%2. What will your user study be compared against
%3. What is the scoring scale
\section{Proposed Evaluation}

We propose to evaluate the system by conducting a micro-study involving one
user. Because our proposed work is to develop a sequential gesture recognition
algorithm, we propose to evaluate the system primarily by collecting metrics
that measure recognition accuracy. During the study, the user will complete an
initial training step an d a subsequent recognition step, consisting of multiple
phases.
Recognition phase \emph{n} will consist of the user providing gesture sequences
of length \emph{n}. We will score the system by computing the proportion of correctly identified individual gestures, where ``correct identification" includes both placement of the individual gesture in each gesture sequence and correct identification of the intended gesture. We will then compare our results for individual gesture recognition with \cite{tanguay_jr_hidden_1995} and those for multiple gesture recognition with \cite{yang_gesture_1994}.
%(Let me call this eval2).
%Do we need to mention that eval2 will most likely be lower than what was achieved in Yang's paper, but since our method involves significantly smaller training time, that its alright?
%I guess this is exactly what the review panel wanted right?

In addition, we will ask for qualitative feedback about the usability and
usefulness of the system compared to the normal methods that the user employs to complete his task.

%----------------------------------------------------------------------------------------
\section{References}

\begin{spacing}{0.9}
\bibliographystyle{unsrt}	%I use unsrt so that the bib items appear in the order of citing
%\bibliography{myrefs}
\begingroup
\renewcommand{\section}[2]{}%
\bibliography{myrefs}
\endgroup
\end{spacing}

\end{multicols}
\end{document}

%	Member #1: Justin Permar - GT ID:902931271
%	Member #2: Arvind Krishnaa Jagannathan - GT ID: 902891874
%