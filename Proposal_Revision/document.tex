%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% LaTeX Template
% Version 1.0 (25/8/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside]{article}

\usepackage{cite} % Better citations
\usepackage{setspace}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.00} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

%\usepackage[hmarginratio=1:1,top=16mm,columnsep=20pt]{geometry} % Document margins

\usepackage[headsep=0.05in,scale=1.0,margin={0.5in,0.5in},columnsep=20pt]{geometry}
%\oddsidemargin 0.0in %%this makes the odd side margin go to the default of 1inch
%\evensidemargin 0.0in
%\headheight 0.5in
%\topmargin 0.5in
%\textheight 9.0in
%\textwidth 6.5in %%sets the textwidth to 6.5, which leaves 1 for the remaining right margin with 8 1/2X11inch paper 

\usepackage{multicol} % Used for the two-column layout of the document
%\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\renewcommand{\LettrineTextFont}{\rmfamily}
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\pagestyle{empty} % no page numbers in footer
\usepackage{scalefnt} %scale font for title
\usepackage{titlesec} % Allows customization of titles
\usepackage{comment}	%Allows addition of comments
%\usepackage[small,compact]{titlesec}
\titleformat{\section}[block]{\large\scshape\centering{\Roman{section}.}}{}{1em}{} % Change the look of the section titles 

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

%\title{\vspace{-15mm}\fontsize{20pt}{5pt}\selectfont\textbf{Experienced Search}} % Article title

%----------------------------------------------------------------------------------------

\begin{document}
%\title{\vspace{-20mm}{On-Line Recognition of Continuous Mouse Gesture Sequences}}
%\date{}
%\maketitle % Insert title
\scalefont{2}
\centerline{Recognition of Continuous Mouse Gesture Sequences}
\normalsize

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\begin{multicols}{2} % Two-column layout throughout the main article text

\section{Problem Statement}

\lettrine[nindent=0em,lines=2]{G}estures, ranging from simple mouse movement to
complex full-body motion, are a common form of input in human-centric user
interfaces\cite{mitra_gesture_2007}. However, a significant barrier to
widespread use of gesture input is the problem of accurate gesture recognition,
both in isolation and in sequence. Gesture recognition frequently involves
solving two problems: segmentation of a gesture sequence and recognition of
individual gestures.

We focus on the problem of utilizing temporal segmentation to identify individual gestures in a sequence of on-line arbitrary mouse gestures. We strive to be part of a larger endeavor of developing a medium of communication for deaf people who are unable to interact through sign language due to partial paralysis or other similar conditions. Although a mouse may not be the most viable medium for such affected people to use to communicate with others, our work may be suitably enhanced/extended for more accessible mediums of interaction.

\begin{comment}
Our work addresses one part of the larger problem of recognition of custom handwritten symbols, which according to law enforcement is a common medium of communication among gangs\cite{lyddane_donald_united_2006}. To our
knowledge, designing a general-purpose ``symbol'' recognizer has not been addressed in the literature.
\end{comment}
%------------------------------------------------
%How are/where are you references deficient
\section{Related Work}

Yang et al \cite{yang_gesture_1994} present work on recognition of individual
gestures in continuous gesture sequences, but unlike our work, they train Hidden Markov Models (HMMs)
on continuous gestures; we view this as a deficiency due to the \emph{a priori}
definition of gesture sequences. The work most closely
related to our problem and approach is focused on recognition of Chinese
handwriting\cite{hong1998segmentation}. Hong et al use an iterative
segmentation technique that uses whitespace separation to split character
sequences into individual characters. Their approach is similar to ours, but is intended to be suitable for both off-line and on-line recognition problems, and thus does not
take advantage of the temporal data that we employ. To our knowledge, there is
no directly comparable system in the literature; however, we will compare our
results to those presented by Hong et al\cite{hong1998segmentation} due to the
similarities between our problem and approach.

%------------------------------------------------
%Why does your approach make sense
\section{Proposed Implementation}

Our problem is segmentation of user-defined gestures. As a result, we
cannot leverage grammar or other linguistic features, as was done successfully
by Starner et al\cite{starner1994line}. Additionally, we cannot
assume the existence of any markers that separate gestures, as is typically found in Chinese
writing\cite{hong1998segmentation}. As a result, we employ an approach based on
an efficient ``search" over the space of segmented gesture sequences, aiming to
find the most accurate gesture segmentation.

We will build upon the mouse gesture recognition system developed by
Tanguay\cite{tanguay_jr_hidden_1995}, which performs on-line recognition of
individual mouse gestures via HMMs. We will enhance his system by adding a segmentation
routine that accurately splits a continuous gesture sequence.

In our approach, we first split the multi-gesture data stream temporally into N
sub-streams (each corresponding to an individual gesture) of identical duration
equal to the mean time taken to draw an individual gesture (calculated from the
training set). The duration of each sub-stream can be conceptualized as a
``window'' overlaid on the complete data stream; N sub-streams correspond to N
windows. After configuring the initial ``window set", we calculate a ``window
set score", which is the mean of all the individual window scores; each window
score, in turn, is equal to the maximum of the probabilities of a match between
the window data and each trained HMM. We subsequently iteratively increase the
window set score by independently increasing or decreasing the duration of each
window by a delta based on the time variance of gestures in the training set. If
the window score increased between iterations \emph{k} and \emph{k-1}, we repeat
the previous action; otherwise, we try the other action. Our routine terminates
when the delta change reaches zero.

%------------------------------------------------
%1. What are you comparing against
%2. What will your user study be compared against
%3. What is the scoring scale
\section{Proposed Evaluation}

We propose to evaluate our routine by measuring the success rate for segmenting
a gesture sequence into the correct gestures. We define the success rate as the
percentage of correctly identified individual gestures. As noted above, our problem
and segmentation routine is comparable with the work completed by Hong et
al\cite{hong1998segmentation}. As a result, we will compare our success rates
with their published results.

To avoid author bias during evaluation, we will conduct a micro-study involving
one user. The user will arbitrarily create gesture sequences of
lengths 1, 2, and 3. Gestures with length 1 serves to validate the system
accuracy for individual gestures. Gestures of lengths 2 and 3 serves to quantify
the success rate of our segmentation routine.

%----------------------------------------------------------------------------------------
\section{References}

\begin{spacing}{0.9}
\bibliographystyle{unsrt}	%I use unsrt so that the bib items appear in the order of citing
%\bibliography{myrefs}
\begingroup
\renewcommand{\section}[2]{}%
\bibliography{myrefs}
\endgroup
\end{spacing}

\end{multicols}
\end{document}

%	Member #1: Justin Permar - GT ID:902931271
%	Member #2: Arvind Krishnaa Jagannathan - GT ID: 902891874
%